# üìö Introduction to Amazon SageMaker

[**‚¨ÖÔ∏è Retornar**](../../index.html)

---

## üì∫ V√≠deo

<div class="video-container" style="text-align: center;">
    <iframe
        style="max-width: 750px; width: 100%; height: 422px;"
        src="https://www.youtube.com/embed/MkptGsCmtQ4?si=JBGNVS4i4GNMwODJ"
        title="Introduction to Amazon SageMaker"
        frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
        referrerpolicy="strict-origin-when-cross-origin"
        allowfullscreen
    ></iframe>
</div>

---

<style>
.columns {
    display: flex;
    gap: 30px;
    align-items: flex-start;
}
.column {
    flex: 1;
    min-width: 300px;
}
p {
    margin-bottom: 1rem;
}
</style>

<div class="columns">

<div class="column">

### English

<p>Hi everyone. In this video, we'll talk about how you can test, deploy, and customized configurations for your AI models for use in Google Kubernetes Engine. Before we dive in, you should Engine.</p>
<p>Before we dive in, you should have a basic understanding of Kubernetes concepts and machine learning. GKE is a managed Kubernetes service that makes it easy to deploy, manage, and scale your a IML workloads in the cloud without needing to be a Kubernetes expert. Let's needing to be a Kubernetes expert.</p>
<p>Let's needing to be a Kubernetes expert. Let's look at how GKE can help you build powerful AIdriven applications. Imagine a machine learning engineer named Max. Max is tasked with building a text summarization system and decides to explore his options on the Google Cloud explore his</p>
<p>options on the Google Cloud console. GKE supports a vast collection of pre-trained multimodel foundation models that are sourced from repositories such as Model Garden and Hugging Face. Max finds a pre-trained Hugging Face.</p>
<p>Max finds a pre-trained large language model that aligns with his company's needs. He recognizes the need for a low latency solution. So, Max specifies his target latency. Based on these settings, GKE recommends a hardware configuration with more</p>
<p>powerful GPUs, helping save time and ensure peak model performance. Max deploys the model with the recommended configuration, resulting in significantly improved response times.</p>
<p>To ensure the model's performance and health, Max monitors its metrics in the GKE console. He tracks metrics like GPU or TPU utilization, request latency, and error rates. By analyzing these metrics, error rates.</p>
<p>By analyzing these metrics, he can identify potential bottlenecks and take corrective actions such as scaling the deployment or optimizing the model. By deploying models on GKE, you can implement a robust productionready serving solution with all the benefits serving</p>
<p>solution with all the benefits of managed Kubernetes. For more information, check out our documentation. Thanks for watching.</p>

</div>

<div class="column">

### Tradu√ß√£o

<p>Oi pessoal.Neste v√≠deo, falaremos sobre como voc√™ pode testar, implantar e personalizar configura√ß√µes para seus modelos de IA para uso no Google Kubernetes Engine.Antes de come√ßarmos, voc√™ deve usar o Engine.</p>
<p>Antes de come√ßarmos, voc√™ deve ter um conhecimento b√°sico dos conceitos do Kubernetes e do aprendizado de m√°quina.O GKE √© um servi√ßo gerenciado do Kubernetes que facilita a implanta√ß√£o, o gerenciamento e o escalonamento de cargas de trabalho IML na nuvem, sem a necessidade de ser um especialista em Kubernetes.Precisamos ser um especialista em Kubernetes.</p>
<p>Precisamos ser um especialista em Kubernetes.Vejamos como o GKE pode ajudar voc√™ a criar aplicativos avan√ßados baseados em IA.Imagine um engenheiro de aprendizado de m√°quina chamado Max.Max tem a tarefa de criar um sistema de resumo de texto e decide explorar suas op√ß√µes no Google Cloud.</p>
<p>op√ß√µes no console do Google Cloud.O GKE oferece suporte a uma vasta cole√ß√£o de modelos b√°sicos multimodelos pr√©-treinados provenientes de reposit√≥rios como Model Garden e Hugging Face.Max encontra um Hugging Face pr√©-treinado.</p>
<p>Max encontra um modelo de linguagem grande pr√©-treinado que se alinha √†s necessidades de sua empresa.Ele reconhece a necessidade de uma solu√ß√£o de baixa lat√™ncia.Portanto, Max especifica sua lat√™ncia alvo.Com base nessas configura√ß√µes, o GKE recomenda uma configura√ß√£o de hardware com mais</p>
<p>GPUs poderosas, ajudando a economizar tempo e garantir o desempenho m√°ximo do modelo.Max implanta o modelo com a configura√ß√£o recomendada, resultando em tempos de resposta significativamente melhores.</p>
<p>Para garantir o desempenho e a integridade do modelo, Max monitora as m√©tricas no console do GKE.Ele rastreia m√©tricas como utiliza√ß√£o de GPU ou TPU, lat√™ncia de solicita√ß√£o e taxas de erro.Ao analisar essas m√©tricas, as taxas de erro.</p>
<p>Ao analisar essas m√©tricas, ele pode identificar poss√≠veis gargalos e tomar a√ß√µes corretivas, como dimensionar a implanta√ß√£o ou otimizar o modelo.Ao implantar modelos no GKE, voc√™ pode implementar uma solu√ß√£o robusta e pronta para produ√ß√£o com todos os benef√≠cios de veicula√ß√£o</p>
<p>solu√ß√£o com todos os benef√≠cios do Kubernetes gerenciado.Para mais informa√ß√µes, confira nossa documenta√ß√£o.Obrigado por assistir.</p>

</div>

</div>
