# üìö Introduction to Amazon SageMaker

[**‚¨ÖÔ∏è Retornar**](../../index.html)

---

## üì∫ V√≠deo

<div class="video-container" style="text-align: center;">
¬† ¬† <iframe
¬† ¬† ¬† ¬† style="max-width: 750px; width: 100%; height: 422px;"
¬† ¬† ¬† ¬† src="https://www.youtube.com/embed/KnNWlfH0TPU?si=JBGNVS4i4GNMwODJ"
¬† ¬† ¬† ¬† title="Introduction to Amazon SageMaker"
¬† ¬† ¬† ¬† frameborder="0"
¬† ¬† ¬† ¬† allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
¬† ¬† ¬† ¬† referrerpolicy="strict-origin-when-cross-origin"
¬† ¬† ¬† ¬† allowfullscreen
¬† ¬† ></iframe>
</div>

---

<style>
.columns {
¬† ¬† display: flex;
¬† ¬† gap: 30px;
¬† ¬† align-items: flex-start;
}
.column {
¬† ¬† flex: 1;
¬† ¬† min-width: 300px;
}
p {
¬† ¬† margin-bottom: 1rem;
}
</style>

<div class="columns">

<div class="column">

### English

<p>Arise is an observability and uh Arise is an observability and uh evaluation platform. Um it allows machine learning engineers, AI engineers to build, evaluate and then productionize their specific ML or AI uh productionize their specific ML or AI uh productionize their specific ML or AI uh applications. So Arise is a is a tool</p>
<p>applications. So Arise is a is a tool applications. So Arise is a is a tool that is purchasable through the AWS that is purchasable through the AWS that is purchasable through the AWS marketplace. It deploys directly in the marketplace. It deploys directly in the marketplace. It deploys directly in the the AWS cloud and then is powered by</p>
<p>the AWS cloud and then is powered by the AWS cloud and then is powered by those Nvidia GPUs uh in order to serve those Nvidia GPUs uh in order to serve those Nvidia GPUs uh in order to serve clients with the agentic uh evaluation clients with the agentic uh evaluation clients with the agentic uh evaluation platform. Lots of teams, right, want to</p>
<p>platform. Lots of teams, right, want to platform. Lots of teams, right, want to dive into the AI world. they want to dive into the AI world. they want to dive into the AI world. they want to utilize all of this new LLM technology. utilize all of this new LLM technology. utilize all of this new LLM technology. AWS with Bedrock makes it super easy to</p>
<p>AWS with Bedrock makes it super easy to AWS with Bedrock makes it super easy to deploy those models into their their deploy those models into their their deploy those models into their their different environments. They don't need to, you know, own all of that to, you know, own all of that</p>
<p>to, you know, own all of that infrastructure and all of that uh that infrastructure and all of that uh that infrastructure and all of that uh that technology. We are right using Bedrock technology. We are right using Bedrock technology. We are right using Bedrock to deploy various different types of to deploy various different types of</p>
<p>to deploy various different types of models. So be it GPT40, be it the cloud models. So be it GPT40, be it the cloud models. So be it GPT40, be it the cloud sonnet models, teams can plug into to sonnet models, teams can plug into to sonnet models, teams can plug into to bedrock via an API or they can access bedrock via an API or they can access</p>
<p>bedrock via an API or they can access those models and actually interact with those models and actually interact with those models and actually interact with those models directly from bedrock. So those models directly from bedrock. So those models directly from bedrock. So it's just a few clicks and the models it's just a few clicks and the models</p>
<p>it's just a few clicks and the models are there. And from a Nvidia are there. And from a Nvidia are there. And from a Nvidia perspective, we are working pretty closely with their Nemo microservices team. So we've got uh what we're team. So we've got uh what we're team. So we've got uh what we're calling the data flywheel where Arise</p>
<p>calling the data flywheel where Arise calling the data flywheel where Arise helps teams to uh collect  and helps teams to uh collect  and helps teams to uh collect  and analyze how their AI applications are analyze how their AI applications are analyze how their AI applications are performing. Nvidia kind of sits at that</p>
<p>performing. Nvidia kind of sits at that performing. Nvidia kind of sits at that at the base level, provides all of that at the base level, provides all of that at the base level, provides all of that compute power, provides the GPUs and all compute power, provides the GPUs and all</p>
<p>compute power, provides the GPUs and all the the technology to actually run the the technology to actually run the the technology to actually run the models. Um AWS orchestrating the the models. Um AWS orchestrating the the models. Um AWS orchestrating the the model deployments and then Arise is model deployments and then Arise is</p>
<p>model deployments and then Arise is going to sit  at that top level going to sit  at that top level going to sit  at that top level um allowing you to evaluate and and um allowing you to evaluate and and um allowing you to evaluate and and understand how those models are performing once they get into either performing once they get into either</p>
<p>performing once they get into either development or the the production world. development or the the production world. development or the the production world. So we work with a few teams that are So we work with a few teams that are So we work with a few teams that are doing running some fine-tuning pipelines</p>
<p>with uh Nvidia's uh microservices using with uh Nvidia's uh microservices using with uh Nvidia's uh microservices using you know AWS to kind of uh store all of you know AWS to kind of uh store all of you know AWS to kind of uh store all of that data. After running through those that data. After running through those</p>
<p>that data. After running through those services, we are able to to cut down services, we are able to to cut down services, we are able to to cut down latency time. So, lots of teams like to latency time. So, lots of teams like to latency time. So, lots of teams like to work with Nvidia. They give you the work with Nvidia. They give you the</p>
<p>work with Nvidia. They give you the microservices ecosystem, which makes it very easy to do fine-tuning and set up very easy to do fine-tuning and set up very easy to do fine-tuning and set up guardrails for your specific use cases.</p>

</div>

<div class="column">

### Tradu√ß√£o

<p>Arise √© uma observabilidade e, uh, Arise √© uma plataforma de observabilidade e, uh, de avalia√ß√£o.Hum, ele permite que engenheiros de aprendizado de m√°quina e engenheiros de IA construam, avaliem e, em seguida, produzam seu ML ou IA espec√≠fico, produzam seu ML ou IA espec√≠fico, produzam seus aplicativos espec√≠ficos de ML ou IA.Ent√£o Arise √© uma ferramenta</p>
<p>aplica√ß√µes.Ent√£o Arise √© um aplicativo de ferramenta.Portanto, Arise √© uma ferramenta que pode ser adquirida por meio da AWS, que pode ser adquirida por meio da AWS e que pode ser adquirida por meio do mercado AWS.Ele √© implantado diretamente no mercado.Ele √© implantado diretamente no mercado.Ele √© implantado diretamente na nuvem AWS e, em seguida, √© alimentado por</p>
<p>a nuvem AWS e, em seguida, √© alimentado pela nuvem AWS e, em seguida, √© alimentado por aquelas GPUs Nvidia uh, a fim de servir essas GPUs Nvidia uh, a fim de servir essas GPUs Nvidia uh, a fim de atender clientes com os clientes de avalia√ß√£o agentic uh com os clientes de avalia√ß√£o agentic uh com a plataforma de avalia√ß√£o agentic uh.Muitas equipes n√©, querem</p>
<p>plataforma.Muitas equipes, certo, querem plataforma.Muitas equipes querem mergulhar no mundo da IA.eles querem mergulhar no mundo da IA.eles querem mergulhar no mundo da IA.eles desejam utilizar toda essa nova tecnologia LLM.utilizar toda essa nova tecnologia LLM.utilizar toda essa nova tecnologia LLM.AWS com Bedrock torna muito f√°cil</p>
<p>AWS com Bedrock torna muito f√°cil AWS com Bedrock torna muito f√°cil implantar esses modelos em seus diferentes ambientes.Eles n√£o precisam, voc√™ sabe, possuir tudo isso para, voc√™ sabe, possuir tudo isso</p>
<p>para, voc√™ sabe, possuir toda essa infraestrutura e tudo isso, uh, essa infraestrutura e tudo isso, uh, essa infraestrutura e tudo isso, uh, essa tecnologia.Estamos certos ao usar a tecnologia Bedrock.Estamos certos ao usar a tecnologia Bedrock.Estamos certos ao usar o Bedrock para implantar v√°rios tipos diferentes de para implantar v√°rios tipos diferentes de</p>
<p>para implantar v√°rios tipos diferentes de modelos.Assim seja GPT40, sejam os modelos em nuvem.Assim seja GPT40, sejam os modelos em nuvem.Ent√£o, seja GPT40, sejam os modelos de soneto em nuvem, as equipes podem se conectar aos modelos de soneto, as equipes podem se conectar aos modelos de soneto, as equipes podem se conectar ao alicerce por meio de uma API ou podem acessar o alicerce por meio de uma API ou podem acessar</p>
<p>base por meio de uma API ou eles podem acessar esses modelos e realmente interagir com esses modelos e realmente interagir com esses modelos e realmente interagir com esses modelos diretamente da base.Ent√£o, esses modelos diretamente do alicerce.Ent√£o, esses modelos diretamente do alicerce.S√£o apenas alguns cliques e os modelos s√£o apenas alguns cliques e os modelos</p>
<p>s√£o apenas alguns cliques e os modelos est√£o l√°.E de uma Nvidia est√£o l√°.E de uma Nvidia est√£o l√°.E do ponto de vista da Nvidia, estamos trabalhando em estreita colabora√ß√£o com a equipe de microsservi√ßos Nemo.Ent√£o n√≥s temos o que somos, equipe.Ent√£o n√≥s temos o que somos, equipe.Ent√£o, temos o que chamamos de volante de dados onde Arise</p>
<p>chamando o volante de dados onde Arise chama o volante de dados onde Arise ajuda as equipes a coletar e ajuda as equipes a coletar e ajuda as equipes a coletar e analisar como seus aplicativos de IA est√£o analisando como seus aplicativos de IA est√£o analisando o desempenho de seus aplicativos de IA.A Nvidia meio que fica parada nisso</p>
<p>realizando.A Nvidia meio que fica com esse desempenho.A Nvidia meio que fica no n√≠vel b√°sico, fornece tudo isso no n√≠vel b√°sico, fornece tudo isso no n√≠vel b√°sico, fornece todo esse poder de computa√ß√£o, fornece as GPUs e todo o poder de computa√ß√£o, fornece as GPUs e todos</p>
<p>poder de computa√ß√£o, fornece as GPUs e toda a tecnologia para realmente executar a tecnologia para realmente executar a tecnologia para realmente executar os modelos.Um AWS orquestrando os modelos.Um AWS orquestrando os modelos.Um AWS orquestrando as implanta√ß√µes do modelo e ent√£o Arise √© as implanta√ß√µes do modelo e ent√£o Arise √©</p>
<p>implanta√ß√µes de modelo e ent√£o Arise vai ficar naquele n√≠vel superior vai ficar naquele n√≠vel mais alto vai ficar naquele n√≠vel mais alto um permitindo que voc√™ avalie e e um permitindo que voc√™ avalie e e um permitindo que voc√™ avalie e e entenda como esses modelos est√£o funcionando quando eles entram em qualquer um deles</p>
<p>atuando assim que entram no mundo do desenvolvimento ou da produ√ß√£o.desenvolvimento ou o mundo da produ√ß√£o.desenvolvimento ou o mundo da produ√ß√£o.Ent√£o, trabalhamos com algumas equipes que est√£o Ent√£o, trabalhamos com algumas equipes que est√£o Ent√£o, trabalhamos com algumas equipes que est√£o executando alguns ajustes finos de pipelines</p>
<p>com uh microsservi√ßos da Nvidia usando com uh microsservi√ßos da Nvidia usando com uh microsservi√ßos da Nvidia usando voc√™ conhece AWS para armazenar todos voc√™s conhecem AWS para armazenar todos voc√™s conhecem AWS para armazenar todos esses dados.Depois de examinar esses dados.Depois de passar por aqueles</p>
<p>esses dados.Depois de executar esses servi√ßos, podemos reduzir os servi√ßos, podemos reduzir os servi√ßos, podemos reduzir o tempo de lat√™ncia.Portanto, muitas equipes gostam do tempo de lat√™ncia.Portanto, muitas equipes gostam do tempo de lat√™ncia.Portanto, muitas equipes gostam de trabalhar com a Nvidia.Eles d√£o a voc√™ o trabalho com a Nvidia.Eles te d√£o o</p>
<p>trabalhar com Nvidia.Eles fornecem o ecossistema de microsservi√ßos, o que torna muito f√°cil fazer o ajuste fino e configurar muito f√°cil fazer o ajuste fino e configurar muito f√°cil fazer o ajuste fino e configurar prote√ß√µes para seus casos de uso espec√≠ficos.</p>

</div>

</div>
