# üìö No title found

[**‚¨ÖÔ∏è Retornar**](../../index.html)

---

## üì∫ V√≠deo

<div class="video-container" style="text-align: center;">
    <iframe
        style="max-width: 750px; width: 100%; height: 422px;"
        src="https://www.youtube.com/embed/KnNWlfH0TPU?si=JBGNVS4i4GNMwODJ"
        title="No title found"
        frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
        referrerpolicy="strict-origin-when-cross-origin"
        allowfullscreen
    ></iframe>
</div>

---

<style>
.columns {
    display: flex;
    gap: 30px;
    align-items: flex-start;
}
.column {
    flex: 1;
    min-width: 300px;
}
p {
    margin-bottom: 1rem;
}
</style>

<div class="columns">

<div class="column">

### Original (English)

<p>Arize is an observability and evaluation platform. It allows machine learning engineers and AI engineers to build, evaluate, and then productionize their specific ML or AI applications. Arize is a tool that is purchasable through the AWS marketplace. It deploys directly in the AWS cloud and then is powered by those NVIDIA GPUs in order to serve clients with the agentic evaluation platform. Lots of teams want to dive into the AI world. They want to utilize all of this new LLM technology. AWS with Bedrock makes it super easy to deploy those models into their different environments. They don't need to own all of that infrastructure and all of that, that technology.</p>
<p>We are using Bedrock to deploy various different types of models. So be it GPT-4o or be it the Claude Sonnet models, teams can plug into to Bedrock, via an API or they can access those models and actually interact with those models directly from from Bedrock. It's just a few clicks and the models are there. And from a NVIDIA perspective, we are working pretty closely with their NeMo microservices team. We've got what we're calling the data flywheel where Arize helps teams to collect and analyze how their AI applications are performing. NVIDIA kind of sits at that, at the base level, provides all of that compute power, provides the GPUs and all of the technology to actually run the models.</p>
<p>AWS orchestrating the model deployments and then Arize is going to sit at that top level allowing you to evaluate and understand how those models are performing once they get into either development or the production world. We work with a few teams that are doing, running some fine tuning pipelines with NVIDIA's microservices, using AWS to kind of store all of that data. After running through, those services, we are able to cut down latency time. So lots of teams like to work with NVIDIA. They give you the microservices ecosystem, which makes it very easy to do fine tuning and set up guardrails for your specific use cases.</p>

</div>

<div class="column">

### Tradu√ß√£o (Portugu√™s)

<p>Arize √© uma plataforma de observabilidade e avalia√ß√£o.Ele permite que engenheiros de aprendizado de m√°quina e engenheiros de IA criem, avaliem e, em seguida, produzam seus aplicativos espec√≠ficos de ML ou IA.Arize √© uma ferramenta que pode ser adquirida no mercado AWS.Ele √© implantado diretamente na nuvem AWS e, em seguida, √© alimentado por essas GPUs NVIDIA para atender os clientes com a plataforma de avalia√ß√£o de agentes.Muitas equipes querem mergulhar no mundo da IA.Eles querem utilizar toda essa nova tecnologia LLM.AWS com Bedrock torna muito f√°cil implantar esses modelos em seus diferentes ambientes.Eles n√£o precisam possuir toda essa infraestrutura e toda essa tecnologia.</p>
<p>Estamos usando o Bedrock para implantar v√°rios tipos diferentes de modelos.Sejam os modelos GPT-4o ou Claude Sonnet, as equipes podem se conectar ao Bedrock, por meio de uma API ou podem acessar esses modelos e realmente interagir com eles diretamente do Bedrock.S√£o apenas alguns cliques e os modelos est√£o l√°.E do ponto de vista da NVIDIA, estamos trabalhando em estreita colabora√ß√£o com a equipe de microsservi√ßos NeMo.Temos o que chamamos de volante de dados, onde Arize ajuda as equipes a coletar e analisar o desempenho de seus aplicativos de IA.A NVIDIA fica nisso, no n√≠vel b√°sico, fornecendo todo esse poder de computa√ß√£o, fornecendo as GPUs e toda a tecnologia para realmente executar os modelos.</p>
<p>A AWS orquestra as implanta√ß√µes do modelo e, em seguida, o Arize ficar√° no n√≠vel superior, permitindo que voc√™ avalie e entenda o desempenho desses modelos quando entrarem no mundo do desenvolvimento ou da produ√ß√£o.Trabalhamos com algumas equipes que est√£o executando alguns pipelines de ajuste fino com microsservi√ßos da NVIDIA, usando AWS para armazenar todos esses dados.Depois de executar esses servi√ßos, podemos reduzir o tempo de lat√™ncia.Muitas equipes gostam de trabalhar com a NVIDIA.Eles fornecem o ecossistema de microsservi√ßos, o que torna muito f√°cil fazer ajustes finos e configurar prote√ß√µes para seus casos de uso espec√≠ficos.</p>

</div>

</div>
